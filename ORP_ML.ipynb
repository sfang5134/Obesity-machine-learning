{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iIiSphEguM0J"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import random\n",
        "from random import shuffle\n",
        "\n",
        "class DataHandler:\n",
        "    def __init__(self, filepath):\n",
        "        self.filepath = filepath\n",
        "\n",
        "    def read_csv(self):\n",
        "        with open(self.filepath, 'r') as file:\n",
        "            return [line.strip().split(',') for line in file.readlines()]\n",
        "\n",
        "    def train_test_split(self, dataset, split_ratio=0.8):\n",
        "        random.shuffle(dataset)\n",
        "        split_index = int(len(dataset) * split_ratio)\n",
        "        return dataset[:split_index], dataset[split_index:]\n",
        "\n",
        "    def separate_features_labels(self, dataset):\n",
        "        features = [row[:-1] for row in dataset]\n",
        "        labels = [row[-1] for row in dataset]\n",
        "\n",
        "        # Encode categorical features and labels\n",
        "        features, labels = self.encode_categorical(features, labels)\n",
        "\n",
        "        return features, labels\n",
        "\n",
        "    def encode_categorical(self, features, labels):\n",
        "        feature_encodings = [{} for _ in range(len(features[0]))]\n",
        "        label_encoding = {}\n",
        "\n",
        "        encoded_features = []\n",
        "        for feature_row in features:\n",
        "            encoded_row = []\n",
        "            for i, value in enumerate(feature_row):\n",
        "                if value not in feature_encodings[i]:\n",
        "                    feature_encodings[i][value] = len(feature_encodings[i])\n",
        "                encoded_row.append(feature_encodings[i][value])\n",
        "            encoded_features.append(encoded_row)\n",
        "\n",
        "        encoded_labels = []\n",
        "        for label in labels:\n",
        "            if label not in label_encoding:\n",
        "                label_encoding[label] = len(label_encoding)\n",
        "            encoded_labels.append(label_encoding[label])\n",
        "\n",
        "        return encoded_features, encoded_labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "class NaiveBayesClassifier:\n",
        "    def __init__(self):\n",
        "        self.means = {}\n",
        "        self.stds = {}\n",
        "        self.class_probabilities = {}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self._calculate_class_probabilities(y)\n",
        "        self._calculate_means_stds(X, y)\n",
        "\n",
        "    def _calculate_class_probabilities(self, y):\n",
        "        class_counts = {label: y.count(label) for label in set(y)}\n",
        "        total_count = len(y)\n",
        "        self.class_probabilities = {label: count / total_count for label, count in class_counts.items()}\n",
        "\n",
        "    def _calculate_means_stds(self, X, y):\n",
        "        for label in self.class_probabilities:\n",
        "            label_features = [X[i] for i in range(len(X)) if y[i] == label]\n",
        "            self.means[label] = [sum(f) / len(f) for f in zip(*label_features)]\n",
        "            self.stds[label] = [math.sqrt(sum([(x - mean)**2 for x in f]) / len(f)) for mean, f in zip(self.means[label], zip(*label_features))]\n",
        "\n",
        "    def predict_single(self, input_features):\n",
        "        probabilities = {}\n",
        "        for label, _ in self.means.items():\n",
        "            probabilities[label] = self.class_probabilities[label]\n",
        "            for i, feature in enumerate(input_features):\n",
        "                probabilities[label] *= self._calculate_probability(feature, self.means[label][i], self.stds[label][i])\n",
        "        return max(probabilities, key=probabilities.get)\n",
        "\n",
        "    def _calculate_probability(self, x, mean, std):\n",
        "        if std == 0:\n",
        "            return 1 if x == mean else 0\n",
        "        else:\n",
        "            exponent = math.exp(-(math.pow(x-mean, 2) / (2*math.pow(std, 2))))\n",
        "            return (1 / (math.sqrt(2*math.pi) * std)) * exponent\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self.predict_single(features) for features in X]\n",
        "\n",
        "    def classification_report(self, y_true, y_pred):\n",
        "        unique_labels = set(y_true)\n",
        "        report = {}\n",
        "        for label in unique_labels:\n",
        "            tp = sum(1 for i in range(len(y_true)) if y_true[i] == label and y_pred[i] == label)\n",
        "            fp = sum(1 for i in range(len(y_true)) if y_true[i] != label and y_pred[i] == label)\n",
        "            fn = sum(1 for i in range(len(y_true)) if y_true[i] == label and y_pred[i] != label)\n",
        "            tn = sum(1 for i in range(len(y_true)) if y_true[i] != label and y_pred[i] != label)\n",
        "\n",
        "            precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
        "            recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
        "            f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
        "            accuracy = (tp + tn) / len(y_true)\n",
        "\n",
        "            report[label] = {\n",
        "                'Precision': precision,\n",
        "                'Recall': recall,\n",
        "                'F1-score': f1,\n",
        "                'Accuracy': accuracy\n",
        "            }\n",
        "\n",
        "        return report\n"
      ],
      "metadata": {
        "id": "nt62lwv_uTDz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNNClassifier:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def _euclidean_distance(self, point1, point2):\n",
        "        return math.sqrt(sum((x - y) ** 2 for x, y in zip(point1, point2)))\n",
        "\n",
        "    def predict_single(self, input_features):\n",
        "        distances = [(self._euclidean_distance(input_features, x_train), y_train) for x_train, y_train in zip(self.X_train, self.y_train)]\n",
        "        distances.sort(key=lambda x: x[0])\n",
        "        neighbors = [label for _, label in distances[:self.k]]\n",
        "        return max(set(neighbors), key=neighbors.count)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self.predict_single(features) for features in X]\n",
        "\n",
        "    def classification_report(self, y_true, y_pred):\n",
        "        unique_labels = set(y_true)\n",
        "        report = {}\n",
        "        for label in unique_labels:\n",
        "            tp = sum(1 for i in range(len(y_true)) if y_true[i] == label and y_pred[i] == label)\n",
        "            fp = sum(1 for i in range(len(y_true)) if y_true[i] != label and y_pred[i] == label)\n",
        "            fn = sum(1 for i in range(len(y_true)) if y_true[i] == label and y_pred[i] != label)\n",
        "            tn = sum(1 for i in range(len(y_true)) if y_true[i] != label and y_pred[i] != label)\n",
        "\n",
        "            precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
        "            recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
        "            f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
        "            accuracy = (tp + tn) / len(y_true)\n",
        "\n",
        "            report[label] = {\n",
        "                'Precision': precision,\n",
        "                'Recall': recall,\n",
        "                'F1-score': f1,\n",
        "                'Accuracy': accuracy\n",
        "            }\n",
        "\n",
        "        return report"
      ],
      "metadata": {
        "id": "DpatATDjUx96"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SVMClassifier:\n",
        "    def __init__(self, learning_rate=0.001, epochs=1000, lambda_param=0.01):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.lambda_param = lambda_param\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.weights = [0.0] * len(X[0])\n",
        "        self.bias = 0.0\n",
        "        self.y = [-1 if i == 0 else 1 for i in y]\n",
        "\n",
        "        for _ in range(self.epochs):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                condition = self.y[idx] * (sum([w * x for w, x in zip(self.weights, x_i)]) + self.bias) >= 1\n",
        "                if condition:\n",
        "                    self.weights = [w - self.learning_rate * (2 * self.lambda_param * w) for w in self.weights]\n",
        "                else:\n",
        "                    self.weights = [w + self.learning_rate * (x_i[j] * self.y[idx] - 2 * self.lambda_param * w) for j, w in enumerate(self.weights)]\n",
        "                    self.bias += self.learning_rate * self.y[idx]\n",
        "\n",
        "    def predict_single(self, x):\n",
        "        linear_output = sum([w * x_i for w, x_i in zip(self.weights, x)]) + self.bias\n",
        "        return 1 if linear_output >= 0 else 0\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self.predict_single(x) for x in X]\n",
        "\n",
        "    def classification_report(self, y_true, y_pred):\n",
        "        unique_labels = set(y_true)\n",
        "        report = {}\n",
        "        for label in unique_labels:\n",
        "            tp = sum(1 for i in range(len(y_true)) if y_true[i] == label and y_pred[i] == label)\n",
        "            fp = sum(1 for i in range(len(y_true)) if y_true[i] != label and y_pred[i] == label)\n",
        "            fn = sum(1 for i in range(len(y_true)) if y_true[i] == label and y_pred[i] != label)\n",
        "            tn = sum(1 for i in range(len(y_true)) if y_true[i] != label and y_pred[i] != label)\n",
        "\n",
        "            precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
        "            recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
        "            f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
        "            accuracy = (tp + tn) / len(y_true)\n",
        "\n",
        "            report[label] = {\n",
        "                'Precision': precision,\n",
        "                'Recall': recall,\n",
        "                'F1-score': f1,\n",
        "                'Accuracy': accuracy\n",
        "            }\n",
        "\n",
        "        return report"
      ],
      "metadata": {
        "id": "0d5qICciU01w"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    filepath = '/content/Obesity Classification.csv'\n",
        "    data_handler = DataHandler(filepath)\n",
        "    dataset = data_handler.read_csv()\n",
        "    train_set, test_set = data_handler.train_test_split(dataset)\n",
        "\n",
        "    train_features, train_labels = data_handler.separate_features_labels(train_set)\n",
        "    test_features, test_labels = data_handler.separate_features_labels(test_set)\n",
        "\n",
        "    # Naive Bayes\n",
        "    nb_classifier = NaiveBayesClassifier()\n",
        "    nb_classifier.fit(train_features, train_labels)\n",
        "    nb_predictions = nb_classifier.predict(test_features)\n",
        "    nb_report = nb_classifier.classification_report(test_labels, nb_predictions)\n",
        "    print(\"Naive Bayes Classification Report:\")\n",
        "    for label, metrics in nb_report.items():\n",
        "        print(f\"Class {label}:\")\n",
        "        for metric, value in metrics.items():\n",
        "            print(f\"  {metric}: {value:.2f}\")\n",
        "        print()\n",
        "\n",
        "    # K-Nearest Neighbors\n",
        "    knn_classifier = KNNClassifier(k=3)\n",
        "    knn_classifier.fit(train_features, train_labels)\n",
        "    knn_predictions = knn_classifier.predict(test_features)\n",
        "    knn_report = knn_classifier.classification_report(test_labels, knn_predictions)\n",
        "    print(\"KNN Classification Report:\")\n",
        "    for label, metrics in knn_report.items():\n",
        "        print(f\"Class {label}:\")\n",
        "        for metric, value in metrics.items():\n",
        "            print(f\"  {metric}: {value:.2f}\")\n",
        "        print()\n",
        "\n",
        "    # Support Vector Machine\n",
        "    svm_classifier = SVMClassifier()\n",
        "    svm_classifier.fit(train_features, train_labels)\n",
        "    svm_predictions = svm_classifier.predict(test_features)\n",
        "    svm_report = svm_classifier.classification_report(test_labels, svm_predictions)\n",
        "    print(\"SVM Classification Report:\")\n",
        "    for label, metrics in svm_report.items():\n",
        "        print(f\"Class {label}:\")\n",
        "        for metric, value in metrics.items():\n",
        "            print(f\"  {metric}: {value:.2f}\")\n",
        "        print()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZSb1ItKuj4c",
        "outputId": "e255eebe-be60-429d-b730-12ba3c7c61e2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Classification Report:\n",
            "Class 0:\n",
            "  Precision: 0.64\n",
            "  Recall: 0.64\n",
            "  F1-score: 0.64\n",
            "  Accuracy: 0.64\n",
            "\n",
            "Class 1:\n",
            "  Precision: 0.38\n",
            "  Recall: 0.60\n",
            "  F1-score: 0.46\n",
            "  Accuracy: 0.68\n",
            "\n",
            "Class 2:\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1-score: 0.00\n",
            "  Accuracy: 0.82\n",
            "\n",
            "Class 3:\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1-score: 0.00\n",
            "  Accuracy: 0.77\n",
            "\n",
            "KNN Classification Report:\n",
            "Class 0:\n",
            "  Precision: 0.67\n",
            "  Recall: 0.36\n",
            "  F1-score: 0.47\n",
            "  Accuracy: 0.59\n",
            "\n",
            "Class 1:\n",
            "  Precision: 0.43\n",
            "  Recall: 0.60\n",
            "  F1-score: 0.50\n",
            "  Accuracy: 0.73\n",
            "\n",
            "Class 2:\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1-score: 0.00\n",
            "  Accuracy: 0.64\n",
            "\n",
            "Class 3:\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1-score: 0.00\n",
            "  Accuracy: 0.68\n",
            "\n",
            "SVM Classification Report:\n",
            "Class 0:\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1-score: 0.00\n",
            "  Accuracy: 0.45\n",
            "\n",
            "Class 1:\n",
            "  Precision: 0.24\n",
            "  Recall: 1.00\n",
            "  F1-score: 0.38\n",
            "  Accuracy: 0.27\n",
            "\n",
            "Class 2:\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1-score: 0.00\n",
            "  Accuracy: 0.82\n",
            "\n",
            "Class 3:\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1-score: 0.00\n",
            "  Accuracy: 0.91\n",
            "\n"
          ]
        }
      ]
    }
  ]
}